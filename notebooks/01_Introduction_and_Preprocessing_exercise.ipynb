{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d685c48e8dd2865",
   "metadata": {},
   "source": [
    "# Introduction and Preprocessing - Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c4b6fc9bc2e0e32c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T22:24:15.099427Z",
     "start_time": "2024-05-29T22:24:15.096712Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589331f87d566c",
   "metadata": {},
   "source": [
    "## Basic Informations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b73271e9de4fdc",
   "metadata": {},
   "source": [
    "--- \n",
    "Load the macroeconomic_missing dataset from the csv file `macroeconomic_missing.csv`. \n",
    "\n",
    "This is a multivariate time series of US Macroeconomic Data. More info at https://www.statsmodels.org/dev/datasets/generated/macrodata.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "354f049e68db13a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T22:24:15.781285Z",
     "start_time": "2024-05-29T22:24:15.776115Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/macroeconomic_missing.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c5767d167f88ff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Extract basic informations from the time series:\n",
    "- shape of the time series\n",
    "- number of channels\n",
    "- number of points\n",
    "- basic statistics\n",
    "- missing values count\n",
    "\n",
    "*hint: these are all methods of variables of the time series dataframe (`df.something` or `df.something()`)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0abdbaae9b154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "554dca7955a353d5",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae83b457704234",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Plot all channels in a single plot. Make sure that all the time series are readable using the appropriate scale. \n",
    "\n",
    "Does a logarithmic scale work in this case? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb2b7731b6e178",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Plot a boxplot of each channel. \n",
    "\n",
    "*hint: boxplot is a method of the dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc70b64242d4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcd774a18ad88628",
   "metadata": {},
   "source": [
    "## Time Series manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2d232946deb1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Save the channel `tbilrate` into the variable `ts1`, convert it into a numpy array and plot it. \n",
    "`tbilrate` is the quarterly monthly average of the monthly 3-month treasury bill: secondary market rate\n",
    "\n",
    "*Do you notice something strange in the plot? What could be the reason for that?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741a10a020d23f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5239a1c2c6c33fb7",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1f1865a681d7df",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Fill the missing values of `tbilrate` using forward fill and plot the original and imputed time series in the same plot.\n",
    "\n",
    "*bonus: try to use a different imputation method and compare the results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "671363888d82a25e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T22:24:17.598185Z",
     "start_time": "2024-05-29T22:24:17.595958Z"
    }
   },
   "outputs": [],
   "source": [
    "from sktime.transformations.series.impute import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf69f20d9d7c61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbd56eef6ad49111",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Save the channel `infl` (inflation) in the variable `ts2`, converting it into a numpy array. Plot `ts1` (after imputation) and `ts2` in the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6f706fcc1346e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8368c01b134d5a6",
   "metadata": {},
   "source": [
    "## Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84583ee04eccdb24",
   "metadata": {},
   "source": [
    "---\n",
    "`ts2` is very noisy, so try to find out if there are anomalies in the time series. Test at least two methods to detect anomalies and plot the time series with the detected anomalies.\n",
    "\n",
    "*hint: don't go too heavy on the anomalies, try to find the ~5 most obvious ones*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ff66a66d591c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33d4ba908678f679",
   "metadata": {},
   "source": [
    "### Outlier replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd4efce53de925",
   "metadata": {},
   "source": [
    "---\n",
    "Treat the anomalies you found as missing values, and use an imputation method to fill them. Plot the original and imputed time series in the same plot.\n",
    "\n",
    "*hint: again, don't remove too many points, just the most extreme ones*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a76be3250d830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "892b2d50cf0961b8",
   "metadata": {},
   "source": [
    "## Normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cf4d2b21a54eaefa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T22:24:18.535741Z",
     "start_time": "2024-05-29T22:24:18.533296Z"
    }
   },
   "outputs": [],
   "source": [
    "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b64981cba45decc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "From the previous steps, you should have a `ts1_imputed` (after missing values replacement), and a `ts2_imputed` (after anomalies replacement). Convert them to the same scale and plot them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c695c664f3ac4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad597bd1917f7ec0",
   "metadata": {},
   "source": [
    "## Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bb52311b521a794a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T22:24:18.683511Z",
     "start_time": "2024-05-29T22:24:18.680982Z"
    }
   },
   "outputs": [],
   "source": [
    "from sktime.param_est.stationarity import StationarityADF\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sktime.transformations.series.difference import Differencer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dbd6f21382db3d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- test if the two normalized time series are stationary\n",
    "- try the same test after differencing the time series\n",
    "- plot the autocorrelation of the differenced time series\n",
    "- looking at the plots, what's the strongest seasonality in the time series? Do they have some seasonality component in common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79974c319ce3cbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c0b24b18078e2b9",
   "metadata": {},
   "source": [
    "## Decompose the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "20595d0905b6be98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T22:24:19.948249Z",
     "start_time": "2024-05-29T22:24:19.945826Z"
    }
   },
   "outputs": [],
   "source": [
    "from sktime.forecasting.trend import STLForecaster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee8fa4b8d14af48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Decompose the normalized (not differenced) time series into trend, seasonal and residual components.\n",
    "\n",
    "*hint: for the seasonality, use the strongest seasonality (>2) you found from the ACF plot. Each time series can have a different seasonality, so you will probably need to decompose them separately.*\n",
    "\n",
    "- Plot the decomposed parts of time series.\n",
    "\n",
    "- Now compare only the trends of the two time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e14e04bc566f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9306c4775dde1fed",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb2c8f100b2ac05",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Compare the first plot of the time series with the last plot of the trends. What can you say about the time series? \n",
    "\n",
    "Do they have similar trends?\n",
    "\n",
    "What can you say about the seasonality of the time series?\n",
    "\n",
    "What can you say about the residuals of the time series?\n",
    "\n",
    "Did normalization help in comparing the time series?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3811e92f274a063",
   "metadata": {},
   "source": [
    "## Bonus Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "43fa86e10a737673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T22:24:20.715786Z",
     "start_time": "2024-05-29T22:24:20.713273Z"
    }
   },
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return x.rolling(window=w).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b115d31b2b86e",
   "metadata": {},
   "source": [
    "---\n",
    "Can you perform all the steps above at once for `ts1`?\n",
    "\n",
    "*hint: you can use a Pipeline to do that*\n",
    "\n",
    "Start from `ts1` and then:\n",
    "- impute missing values (Imputer)\n",
    "- normalize the time series (TabularToSeriesAdaptor + a scaler of your choice)\n",
    "- deseasonalize the time series (Deseasonalizer)\n",
    "- smooth the time series (with a moving average)\n",
    "- impute missing values (generated by the moving average)\n",
    "\n",
    "Plot the original and the final time series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36cdcbf7e255ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8458ed73dd484391",
   "metadata": {},
   "source": [
    "## Bonus Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f3b84a2f50e84b",
   "metadata": {},
   "source": [
    "Given the following time series (`time_series1`, `time_series2`, `time_series3`, `time_series4`, `time_series5`, make them stationary if necessary, using the appropriate transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f930603f33908",
   "metadata": {},
   "source": [
    "### Time Series 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "32bf81231771c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "n = 100\n",
    "x1 = np.linspace(0, 10, n)\n",
    "noise1 = np.random.normal(0, 1, n)\n",
    "time_series1 = pd.Series(x1 + noise1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c0be9114a40f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86ba4cc6a00d7629",
   "metadata": {},
   "source": [
    "### Time Series 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "99134aa0db0e83ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T22:24:21.130739Z",
     "start_time": "2024-05-29T22:24:21.127284Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "n = 120\n",
    "x2 = 10 * np.sin(np.linspace(0, 3 * np.pi, n))\n",
    "noise2 = np.random.normal(0, 1, n)\n",
    "time_series2 = pd.Series(x2 + noise2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5f8b962904dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9626bb86e8fcd185",
   "metadata": {},
   "source": [
    "### Time Series 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f79e0d1a3d344aba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T22:24:21.145583Z",
     "start_time": "2024-05-29T22:24:21.142989Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "n = 100\n",
    "time_series3 = pd.Series(np.cumsum(np.random.normal(0, 1, n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6767d0ebb0038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98c9860365c35cc3",
   "metadata": {},
   "source": [
    "### Time Series 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d3454443f0b06f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T22:24:21.315809Z",
     "start_time": "2024-05-29T22:24:21.312831Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "n = 100\n",
    "time_series4 = pd.Series(np.exp(np.linspace(0, 3, n)) + np.random.normal(0, 5, n)) + 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da86b8290b0a5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47ef272897e02dfc",
   "metadata": {},
   "source": [
    "### Time Series 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "42a0d6351a9850c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T22:24:21.482315Z",
     "start_time": "2024-05-29T22:24:21.479108Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "n = 150\n",
    "x5 = np.linspace(0, 15, n)\n",
    "sp = 5 * np.sin(np.linspace(0, 5 * np.pi, n))\n",
    "noise5 = np.random.normal(0, 1, n)\n",
    "time_series5 = pd.Series(x5 + sp + noise5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ede18990070d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
